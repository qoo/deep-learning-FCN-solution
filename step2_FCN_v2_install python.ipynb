{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submodule 'submodules/TensorVision' (https://github.com/TensorVision/TensorVision.git) registered for path 'submodules/TensorVision'\n",
      "Submodule 'submodules/tensorflow-fcn' (https://github.com/MarvinTeichmann/tensorflow-fcn.git) registered for path 'submodules/tensorflow-fcn'\n",
      "Cloning into 'submodules/TensorVision'...\n",
      "remote: Counting objects: 661, done.\u001b[K\n",
      "remote: Total 661 (delta 0), reused 0 (delta 0), pack-reused 660\u001b[K\n",
      "Receiving objects: 100% (661/661), 1.18 MiB | 0 bytes/s, done.\n",
      "Resolving deltas: 100% (403/403), done.\n",
      "Checking connectivity... done.\n",
      "Submodule path 'submodules/TensorVision': checked out '0f9a9c1cee19a7bf87f1e699f91df2a9a83c4a8b'\n",
      "Cloning into 'submodules/tensorflow-fcn'...\n",
      "remote: Counting objects: 240, done.\u001b[K\n",
      "remote: Total 240 (delta 0), reused 0 (delta 0), pack-reused 240\u001b[K\n",
      "Receiving objects: 100% (240/240), 288.35 KiB | 0 bytes/s, done.\n",
      "Resolving deltas: 100% (148/148), done.\n",
      "Checking connectivity... done.\n",
      "Submodule path 'submodules/tensorflow-fcn': checked out '86e9c94d2185ce5c9bcb10f8c8cc44dfc2da8164'\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/MarvinTeichmann/KittiSeg\n",
    "!git submodule update --init --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#! curl -O  http://kitti.is.tue.mpg.de/kitti/data_road.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-16 19:50:15,175 INFO Downloading VGG weights.\n",
      "2017-08-16 19:50:15,175 INFO Download URL: ftp://mi.eng.cam.ac.uk/pub/mttt2/models/vgg16.npy\n",
      "2017-08-16 19:50:15,176 INFO Download DIR: DATA\n",
      ">> Downloading vgg16.npy 100.0%\n",
      "2017-08-16 19:50:45,783 INFO Downloading Kitti Road Data.\n",
      "2017-08-16 19:50:45,783 INFO Download URL: http://kitti.is.tue.mpg.de/kitti/data_road.zip\n",
      "2017-08-16 19:50:45,783 INFO Download DIR: DATA\n",
      ">> Downloading data_road.zip 100.0%\n",
      "2017-08-16 19:51:32,713 INFO Extracting kitti_road data.\n",
      "2017-08-16 19:51:36,325 INFO Preparing kitti_road data.\n",
      "2017-08-16 19:51:36,325 INFO All data have been downloaded successful.\n"
     ]
    }
   ],
   "source": [
    "!python download_data.py --kitti_url http://kitti.is.tue.mpg.de/kitti/data_road.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-16 19:57:14,715 INFO No environment variable 'TV_PLUGIN_DIR' found. Set to '/home/ubuntu/tv-plugins'.\n",
      "2017-08-16 19:57:14,715 INFO No environment variable 'TV_STEP_SHOW' found. Set to '50'.\n",
      "2017-08-16 19:57:14,715 INFO No environment variable 'TV_STEP_EVAL' found. Set to '250'.\n",
      "2017-08-16 19:57:14,715 INFO No environment variable 'TV_STEP_WRITE' found. Set to '1000'.\n",
      "2017-08-16 19:57:14,715 INFO No environment variable 'TV_MAX_KEEP' found. Set to '10'.\n",
      "2017-08-16 19:57:14,715 INFO No environment variable 'TV_STEP_STR' found. Set to 'Step {step}/{total_steps}: loss = {loss_value:.2f}; lr = {lr_value:.2e}; {sec_per_batch:.3f} sec (per Batch); {examples_per_sec:.1f} imgs/sec'.\n",
      "2017-08-16 19:57:14,717 INFO Download URL: ftp://mi.eng.cam.ac.uk/pub/mttt2/models/KittiSeg_pretrained.zip\n",
      "2017-08-16 19:57:14,717 INFO Download DIR: RUNS\n",
      "Traceback (most recent call last):\n",
      "  File \"demo.py\", line 227, in <module>\n",
      "    tf.app.run()\n",
      "  File \"/usr/local/anaconda3/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n",
      "    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n",
      "  File \"demo.py\", line 124, in main\n",
      "    maybe_download_and_extract(runs_dir)\n",
      "  File \"demo.py\", line 87, in maybe_download_and_extract\n",
      "    download_name = tv_utils.download(weights_url, runs_dir)\n",
      "  File \"incl/tensorvision/utils.py\", line 48, in download\n",
      "    reporthook=_progress)\n",
      "  File \"/usr/local/anaconda3/lib/python3.5/urllib/request.py\", line 198, in urlretrieve\n",
      "    tfp = open(filename, 'wb')\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'RUNS/KittiSeg_pretrained.zip'\n"
     ]
    }
   ],
   "source": [
    "!python demo.py --input_image data/demo/demo.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2627M  100 2627M    0     0  17.5M      0  0:02:29  0:02:29 --:--:-- 16.9M\n"
     ]
    }
   ],
   "source": [
    "! curl -O  ftp://mi.eng.cam.ac.uk/pub/mttt2/models/KittiSeg_pretrained.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"maybe_download_and_extract(runs_dir):\"\"\"\n",
    "import zipfile\n",
    "runs_dir = 'RUNS'\n",
    "download_name = 'KittiSeg_pretrained.zip'\n",
    "zipfile.ZipFile(download_name, 'r').extractall(runs_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-16 20:00:15,940 INFO No environment variable 'TV_PLUGIN_DIR' found. Set to '/home/ubuntu/tv-plugins'.\n",
      "2017-08-16 20:00:15,940 INFO No environment variable 'TV_STEP_SHOW' found. Set to '50'.\n",
      "2017-08-16 20:00:15,940 INFO No environment variable 'TV_STEP_EVAL' found. Set to '250'.\n",
      "2017-08-16 20:00:15,940 INFO No environment variable 'TV_STEP_WRITE' found. Set to '1000'.\n",
      "2017-08-16 20:00:15,941 INFO No environment variable 'TV_MAX_KEEP' found. Set to '10'.\n",
      "2017-08-16 20:00:15,941 INFO No environment variable 'TV_STEP_STR' found. Set to 'Step {step}/{total_steps}: loss = {loss_value:.2f}; lr = {lr_value:.2e}; {sec_per_batch:.3f} sec (per Batch); {examples_per_sec:.1f} imgs/sec'.\n",
      "2017-08-16 20:00:15,941 INFO f: <_io.TextIOWrapper name='RUNS/KittiSeg_pretrained/model_files/hypes.json' mode='r' encoding='UTF-8'>\n",
      "2017-08-16 20:00:15,942 INFO Hypes loaded successfully.\n",
      "2017-08-16 20:00:15,954 INFO Modules loaded successfully. Starting to build tf graph.\n",
      "npy file loaded\n",
      "Layer name: conv1_1\n",
      "Layer shape: (3, 3, 3, 64)\n",
      "2017-08-16 20:00:16,627 INFO Creating Summary for: conv1_1/filter\n",
      "2017-08-16 20:00:16,646 INFO Creating Summary for: conv1_1/biases\n",
      "Layer name: conv1_2\n",
      "Layer shape: (3, 3, 64, 64)\n",
      "2017-08-16 20:00:16,669 INFO Creating Summary for: conv1_2/filter\n",
      "2017-08-16 20:00:16,686 INFO Creating Summary for: conv1_2/biases\n",
      "Layer name: conv2_1\n",
      "Layer shape: (3, 3, 64, 128)\n",
      "2017-08-16 20:00:16,710 INFO Creating Summary for: conv2_1/filter\n",
      "2017-08-16 20:00:16,728 INFO Creating Summary for: conv2_1/biases\n",
      "Layer name: conv2_2\n",
      "Layer shape: (3, 3, 128, 128)\n",
      "2017-08-16 20:00:16,751 INFO Creating Summary for: conv2_2/filter\n",
      "2017-08-16 20:00:16,769 INFO Creating Summary for: conv2_2/biases\n",
      "Layer name: conv3_1\n",
      "Layer shape: (3, 3, 128, 256)\n",
      "2017-08-16 20:00:16,793 INFO Creating Summary for: conv3_1/filter\n",
      "2017-08-16 20:00:16,811 INFO Creating Summary for: conv3_1/biases\n",
      "Layer name: conv3_2\n",
      "Layer shape: (3, 3, 256, 256)\n",
      "2017-08-16 20:00:16,837 INFO Creating Summary for: conv3_2/filter\n",
      "2017-08-16 20:00:16,854 INFO Creating Summary for: conv3_2/biases\n",
      "Layer name: conv3_3\n",
      "Layer shape: (3, 3, 256, 256)\n",
      "2017-08-16 20:00:16,879 INFO Creating Summary for: conv3_3/filter\n",
      "2017-08-16 20:00:16,897 INFO Creating Summary for: conv3_3/biases\n",
      "Layer name: conv4_1\n",
      "Layer shape: (3, 3, 256, 512)\n",
      "2017-08-16 20:00:16,926 INFO Creating Summary for: conv4_1/filter\n",
      "2017-08-16 20:00:16,944 INFO Creating Summary for: conv4_1/biases\n",
      "Layer name: conv4_2\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-08-16 20:00:16,979 INFO Creating Summary for: conv4_2/filter\n",
      "2017-08-16 20:00:16,997 INFO Creating Summary for: conv4_2/biases\n",
      "Layer name: conv4_3\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-08-16 20:00:17,027 INFO Creating Summary for: conv4_3/filter\n",
      "2017-08-16 20:00:17,045 INFO Creating Summary for: conv4_3/biases\n",
      "Layer name: conv5_1\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-08-16 20:00:17,076 INFO Creating Summary for: conv5_1/filter\n",
      "2017-08-16 20:00:17,094 INFO Creating Summary for: conv5_1/biases\n",
      "Layer name: conv5_2\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-08-16 20:00:17,125 INFO Creating Summary for: conv5_2/filter\n",
      "2017-08-16 20:00:17,144 INFO Creating Summary for: conv5_2/biases\n",
      "Layer name: conv5_3\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-08-16 20:00:17,174 INFO Creating Summary for: conv5_3/filter\n",
      "2017-08-16 20:00:17,191 INFO Creating Summary for: conv5_3/biases\n",
      "Layer name: fc6\n",
      "Layer shape: [7, 7, 512, 4096]\n",
      "2017-08-16 20:00:17,708 INFO Creating Summary for: fc6/weights\n",
      "2017-08-16 20:00:17,726 INFO Creating Summary for: fc6/biases\n",
      "Layer name: fc7\n",
      "Layer shape: [1, 1, 4096, 4096]\n",
      "2017-08-16 20:00:17,833 INFO Creating Summary for: fc7/weights\n",
      "2017-08-16 20:00:17,851 INFO Creating Summary for: fc7/biases\n",
      "2017-08-16 20:00:17,878 INFO Creating Summary for: score_fr/weights\n",
      "2017-08-16 20:00:17,895 INFO Creating Summary for: score_fr/biases\n",
      "2017-08-16 20:00:17,929 INFO Creating Summary for: upscore2/up_filter\n",
      "2017-08-16 20:00:17,955 INFO Creating Summary for: score_pool4/weights\n",
      "2017-08-16 20:00:17,974 INFO Creating Summary for: score_pool4/biases\n",
      "2017-08-16 20:00:18,005 INFO Creating Summary for: upscore4/up_filter\n",
      "2017-08-16 20:00:18,031 INFO Creating Summary for: score_pool3/weights\n",
      "2017-08-16 20:00:18,049 INFO Creating Summary for: score_pool3/biases\n",
      "2017-08-16 20:00:18,084 INFO Creating Summary for: upscore32/up_filter\n",
      "2017-08-16 20:00:18,108 INFO Graph build successfully.\n",
      "2017-08-16 20:00:18.108722: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-08-16 20:00:18.108773: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-08-16 20:00:18.108789: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-08-16 20:00:18.108801: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-08-16 20:00:18.108813: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-08-16 20:00:18.310272: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2017-08-16 20:00:18.310804: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: \n",
      "name: Tesla K80\n",
      "major: 3 minor: 7 memoryClockRate (GHz) 0.8235\n",
      "pciBusID 0000:00:1e.0\n",
      "Total memory: 11.17GiB\n",
      "Free memory: 11.11GiB\n",
      "2017-08-16 20:00:18.310858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \n",
      "2017-08-16 20:00:18.310873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \n",
      "2017-08-16 20:00:18.310892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0)\n",
      "2017-08-16 20:00:18,457 INFO /u/marvin/no_backup/RUNS/KittiSeg/loss_bench/xentropy_kitti_fcn_2016_10_15_01.18/model.ckpt-15999\n",
      "INFO:tensorflow:Restoring parameters from RUNS/KittiSeg_pretrained/model.ckpt-15999\n",
      "2017-08-16 20:00:18,457 INFO Restoring parameters from RUNS/KittiSeg_pretrained/model.ckpt-15999\n",
      "2017-08-16 20:00:20,798 INFO Weights loaded successfully.\n",
      "2017-08-16 20:00:20,798 INFO Starting inference using data/demo/demo.png as input\n",
      "2017-08-16 20:00:35,886 INFO \n",
      "2017-08-16 20:00:35,886 INFO Raw output image has been saved to: /mnt/KittiSeg/data/demo/demo_raw.png\n",
      "2017-08-16 20:00:35,886 INFO Red-Blue overlay of confs have been saved to: /mnt/KittiSeg/data/demo/demo_rb.png\n",
      "2017-08-16 20:00:35,886 INFO Green plot of predictions have been saved to: /mnt/KittiSeg/data/demo/demo_green.png\n",
      "2017-08-16 20:00:35,886 INFO \n",
      "2017-08-16 20:00:35,886 WARNING Do NOT use this Code to evaluate multiple images.\n",
      "2017-08-16 20:00:35,886 WARNING Demo.py is **very slow** and designed to be a tutorial to show how the KittiSeg works.\n",
      "2017-08-16 20:00:35,886 WARNING \n",
      "2017-08-16 20:00:35,886 WARNING Please see this comment, if you like to apply demo.py tomultiple images see:\n",
      "2017-08-16 20:00:35,887 WARNING https://github.com/MarvinTeichmann/KittiBox/issues/15#issuecomment-301800058\n"
     ]
    }
   ],
   "source": [
    "!python demo.py --input_image data/demo/demo.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-31 20:24:28,769 INFO No environment variable 'TV_PLUGIN_DIR' found. Set to '/home/ubuntu/tv-plugins'.\n",
      "2017-07-31 20:24:28,769 INFO No environment variable 'TV_STEP_SHOW' found. Set to '50'.\n",
      "2017-07-31 20:24:28,769 INFO No environment variable 'TV_STEP_EVAL' found. Set to '250'.\n",
      "2017-07-31 20:24:28,769 INFO No environment variable 'TV_STEP_WRITE' found. Set to '1000'.\n",
      "2017-07-31 20:24:28,770 INFO No environment variable 'TV_MAX_KEEP' found. Set to '10'.\n",
      "2017-07-31 20:24:28,770 INFO No environment variable 'TV_STEP_STR' found. Set to 'Step {step}/{total_steps}: loss = {loss_value:.2f}; lr = {lr_value:.2e}; {sec_per_batch:.3f} sec (per Batch); {examples_per_sec:.1f} imgs/sec'.\n",
      "2017-07-31 20:24:28,770 INFO f: <_io.TextIOWrapper name='RUNS/KittiSeg_pretrained/model_files/hypes.json' mode='r' encoding='UTF-8'>\n",
      "2017-07-31 20:24:28,771 INFO Hypes loaded successfully.\n",
      "2017-07-31 20:24:28,773 INFO Modules loaded successfully. Starting to build tf graph.\n",
      "npy file loaded\n",
      "Layer name: conv1_1\n",
      "Layer shape: (3, 3, 3, 64)\n",
      "2017-07-31 20:24:29,429 INFO Creating Summary for: conv1_1/filter\n",
      "2017-07-31 20:24:29,449 INFO Creating Summary for: conv1_1/biases\n",
      "Layer name: conv1_2\n",
      "Layer shape: (3, 3, 64, 64)\n",
      "2017-07-31 20:24:29,473 INFO Creating Summary for: conv1_2/filter\n",
      "2017-07-31 20:24:29,490 INFO Creating Summary for: conv1_2/biases\n",
      "Layer name: conv2_1\n",
      "Layer shape: (3, 3, 64, 128)\n",
      "2017-07-31 20:24:29,514 INFO Creating Summary for: conv2_1/filter\n",
      "2017-07-31 20:24:29,531 INFO Creating Summary for: conv2_1/biases\n",
      "Layer name: conv2_2\n",
      "Layer shape: (3, 3, 128, 128)\n",
      "2017-07-31 20:24:29,553 INFO Creating Summary for: conv2_2/filter\n",
      "2017-07-31 20:24:29,570 INFO Creating Summary for: conv2_2/biases\n",
      "Layer name: conv3_1\n",
      "Layer shape: (3, 3, 128, 256)\n",
      "2017-07-31 20:24:29,594 INFO Creating Summary for: conv3_1/filter\n",
      "2017-07-31 20:24:29,611 INFO Creating Summary for: conv3_1/biases\n",
      "Layer name: conv3_2\n",
      "Layer shape: (3, 3, 256, 256)\n",
      "2017-07-31 20:24:29,637 INFO Creating Summary for: conv3_2/filter\n",
      "2017-07-31 20:24:29,654 INFO Creating Summary for: conv3_2/biases\n",
      "Layer name: conv3_3\n",
      "Layer shape: (3, 3, 256, 256)\n",
      "2017-07-31 20:24:29,678 INFO Creating Summary for: conv3_3/filter\n",
      "2017-07-31 20:24:29,695 INFO Creating Summary for: conv3_3/biases\n",
      "Layer name: conv4_1\n",
      "Layer shape: (3, 3, 256, 512)\n",
      "2017-07-31 20:24:29,722 INFO Creating Summary for: conv4_1/filter\n",
      "2017-07-31 20:24:29,739 INFO Creating Summary for: conv4_1/biases\n",
      "Layer name: conv4_2\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-07-31 20:24:29,773 INFO Creating Summary for: conv4_2/filter\n",
      "2017-07-31 20:24:29,790 INFO Creating Summary for: conv4_2/biases\n",
      "Layer name: conv4_3\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-07-31 20:24:29,819 INFO Creating Summary for: conv4_3/filter\n",
      "2017-07-31 20:24:29,836 INFO Creating Summary for: conv4_3/biases\n",
      "Layer name: conv5_1\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-07-31 20:24:29,866 INFO Creating Summary for: conv5_1/filter\n",
      "2017-07-31 20:24:29,883 INFO Creating Summary for: conv5_1/biases\n",
      "Layer name: conv5_2\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-07-31 20:24:29,913 INFO Creating Summary for: conv5_2/filter\n",
      "2017-07-31 20:24:29,930 INFO Creating Summary for: conv5_2/biases\n",
      "Layer name: conv5_3\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-07-31 20:24:29,959 INFO Creating Summary for: conv5_3/filter\n",
      "2017-07-31 20:24:29,977 INFO Creating Summary for: conv5_3/biases\n",
      "Layer name: fc6\n",
      "Layer shape: [7, 7, 512, 4096]\n",
      "2017-07-31 20:24:30,491 INFO Creating Summary for: fc6/weights\n",
      "2017-07-31 20:24:30,509 INFO Creating Summary for: fc6/biases\n",
      "Layer name: fc7\n",
      "Layer shape: [1, 1, 4096, 4096]\n",
      "2017-07-31 20:24:30,618 INFO Creating Summary for: fc7/weights\n",
      "2017-07-31 20:24:30,635 INFO Creating Summary for: fc7/biases\n",
      "2017-07-31 20:24:30,660 INFO Creating Summary for: score_fr/weights\n",
      "2017-07-31 20:24:30,677 INFO Creating Summary for: score_fr/biases\n",
      "2017-07-31 20:24:30,708 INFO Creating Summary for: upscore2/up_filter\n",
      "2017-07-31 20:24:30,734 INFO Creating Summary for: score_pool4/weights\n",
      "2017-07-31 20:24:30,751 INFO Creating Summary for: score_pool4/biases\n",
      "2017-07-31 20:24:30,781 INFO Creating Summary for: upscore4/up_filter\n",
      "2017-07-31 20:24:30,806 INFO Creating Summary for: score_pool3/weights\n",
      "2017-07-31 20:24:30,823 INFO Creating Summary for: score_pool3/biases\n",
      "2017-07-31 20:24:30,854 INFO Creating Summary for: upscore32/up_filter\n",
      "2017-07-31 20:24:30,878 INFO Graph build successfully.\n",
      "2017-07-31 20:24:30.879029: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-31 20:24:30.879068: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-31 20:24:30.879082: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-31 20:24:30.879094: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-31 20:24:30.879105: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-31 20:24:31.065798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2017-07-31 20:24:31.066347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: \n",
      "name: Tesla K80\n",
      "major: 3 minor: 7 memoryClockRate (GHz) 0.8235\n",
      "pciBusID 0000:00:1e.0\n",
      "Total memory: 11.17GiB\n",
      "Free memory: 11.11GiB\n",
      "2017-07-31 20:24:31.066400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \n",
      "2017-07-31 20:24:31.066415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \n",
      "2017-07-31 20:24:31.066434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0)\n",
      "2017-07-31 20:24:31,208 INFO /u/marvin/no_backup/RUNS/KittiSeg/loss_bench/xentropy_kitti_fcn_2016_10_15_01.18/model.ckpt-15999\n",
      "INFO:tensorflow:Restoring parameters from RUNS/KittiSeg_pretrained/model.ckpt-15999\n",
      "2017-07-31 20:24:31,208 INFO Restoring parameters from RUNS/KittiSeg_pretrained/model.ckpt-15999\n",
      "2017-07-31 20:24:33,275 INFO Weights loaded successfully.\n",
      "2017-07-31 20:24:33,275 INFO Starting inference using data/demo/test2.png as input\n",
      "2017-07-31 20:24:35,138 INFO \n",
      "2017-07-31 20:24:35,138 INFO Raw output image has been saved to: /mnt/KittiSeg/data/demo/test2_raw.png\n",
      "2017-07-31 20:24:35,138 INFO Red-Blue overlay of confs have been saved to: /mnt/KittiSeg/data/demo/test2_rb.png\n",
      "2017-07-31 20:24:35,138 INFO Green plot of predictions have been saved to: /mnt/KittiSeg/data/demo/test2_green.png\n",
      "2017-07-31 20:24:35,138 INFO \n",
      "2017-07-31 20:24:35,138 WARNING Do NOT use this Code to evaluate multiple images.\n",
      "2017-07-31 20:24:35,139 WARNING Demo.py is **very slow** and designed to be a tutorial to show how the KittiSeg works.\n",
      "2017-07-31 20:24:35,139 WARNING \n",
      "2017-07-31 20:24:35,139 WARNING Please see this comment, if you like to apply demo.py tomultiple images see:\n",
      "2017-07-31 20:24:35,139 WARNING https://github.com/MarvinTeichmann/KittiBox/issues/15#issuecomment-301800058\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test google image\"\"\"\n",
    "!python demo.py --input_image data/demo/test2.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import commentjson\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"train.py\", line 18, in <module>\r\n",
      "    import commentjson\r\n",
      "  File \"/usr/local/anaconda3/lib/python3.5/site-packages/commentjson/__init__.py\", line 1, in <module>\r\n",
      "    from commentjson import dump\r\n",
      "ImportError: cannot import name 'dump'\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --hypes hypes/KittiSeg.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting commentjson\n",
      "  Downloading commentjson-0.6.tar.gz\n",
      "Building wheels for collected packages: commentjson\n",
      "  Running setup.py bdist_wheel for commentjson ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/ubuntu/.cache/pip/wheels/d4/8e/dc/4a85a7fd1d9c8e161987399ead8a56f95042faba79d1f436c3\n",
      "Successfully built commentjson\n",
      "Installing collected packages: commentjson\n",
      "Successfully installed commentjson-0.6\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install commentjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dump\n",
      "  Using cached dump-0.0.1.tar.gz\n",
      "    Complete output from command python setup.py egg_info:\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-build-qjp3d40t/dump/setup.py\", line 12, in <module>\n",
      "        for node in (n for n in ast.parse(f.read()).body if isinstance(n, ast.Assign)):\n",
      "      File \"/usr/local/anaconda3/lib/python3.5/ast.py\", line 35, in parse\n",
      "        return compile(source, filename, mode, PyCF_ONLY_AST)\n",
      "      File \"<unknown>\", line 70\n",
      "        print \"This should be the help part that prints out all the commands\"\n",
      "                                                                            ^\n",
      "    SyntaxError: Missing parentheses in call to 'print'\n",
      "    \n",
      "    ----------------------------------------\n",
      "\u001b[31mCommand \"python setup.py egg_info\" failed with error code 1 in /tmp/pip-build-qjp3d40t/dump/\u001b[0m\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"train.py\", line 18, in <module>\r\n",
      "    import commentjson\r\n",
      "  File \"/usr/local/anaconda3/lib/python3.5/site-packages/commentjson/__init__.py\", line 1, in <module>\r\n",
      "    from commentjson import dump\r\n",
      "ImportError: cannot import name 'dump'\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --hypes hypes/KittiSeg.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"train.py\", line 18, in <module>\r\n",
      "    import commentjson\r\n",
      "  File \"/usr/local/anaconda3/lib/python3.5/site-packages/commentjson/__init__.py\", line 1, in <module>\r\n",
      "    from commentjson import dump\r\n",
      "ImportError: cannot import name 'dump'\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --hypes hypes/KittiSeg.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  485M  100  485M    0     0  68.5M      0  0:00:07  0:00:07 --:--:-- 69.3M\n"
     ]
    }
   ],
   "source": [
    "! curl -O https://repo.continuum.io/archive/Anaconda2-4.4.0-Linux-x86_64.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! mkdir DATA/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! cp DATA/vgg16.npy DATA/weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-16 20:15:15,475 INFO No environment variable 'TV_PLUGIN_DIR' found. Set to '/home/ubuntu/tv-plugins'.\n",
      "2017-08-16 20:15:15,475 INFO No environment variable 'TV_STEP_SHOW' found. Set to '50'.\n",
      "2017-08-16 20:15:15,475 INFO No environment variable 'TV_STEP_EVAL' found. Set to '250'.\n",
      "2017-08-16 20:15:15,475 INFO No environment variable 'TV_STEP_WRITE' found. Set to '1000'.\n",
      "2017-08-16 20:15:15,475 INFO No environment variable 'TV_MAX_KEEP' found. Set to '10'.\n",
      "2017-08-16 20:15:15,476 INFO No environment variable 'TV_STEP_STR' found. Set to 'Step {step}/{total_steps}: loss = {loss_value:.2f}; lr = {lr_value:.2e}; {sec_per_batch:.3f} sec (per Batch); {examples_per_sec:.1f} imgs/sec'.\n",
      "2017-08-16 20:15:15,477 INFO f: <open file 'hypes/KittiSeg.json', mode 'r' at 0x7f70d836f420>\n",
      "2017-08-16 20:15:15,478 INFO Initialize training folder\n",
      "2017-08-16 20:15:15,480 INFO Start training\n",
      "2017-08-16 20:15:15.482022: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-08-16 20:15:15.482062: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-08-16 20:15:15.482077: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-08-16 20:15:15.482089: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-08-16 20:15:15.482100: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-08-16 20:15:15.600891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2017-08-16 20:15:15.601415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties: \n",
      "name: Tesla K80\n",
      "major: 3 minor: 7 memoryClockRate (GHz) 0.8235\n",
      "pciBusID 0000:00:1e.0\n",
      "Total memory: 11.17GiB\n",
      "Free memory: 11.11GiB\n",
      "2017-08-16 20:15:15.601466: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0 \n",
      "2017-08-16 20:15:15.601480: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y \n",
      "2017-08-16 20:15:15.601501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0)\n",
      "npy file loaded\n",
      "Layer name: conv1_1\n",
      "Layer shape: (3, 3, 3, 64)\n",
      "2017-08-16 20:15:16,202 INFO Creating Summary for: conv1_1/filter\n",
      "2017-08-16 20:15:16,219 INFO Creating Summary for: conv1_1/biases\n",
      "Layer name: conv1_2\n",
      "Layer shape: (3, 3, 64, 64)\n",
      "2017-08-16 20:15:16,242 INFO Creating Summary for: conv1_2/filter\n",
      "2017-08-16 20:15:16,260 INFO Creating Summary for: conv1_2/biases\n",
      "Layer name: conv2_1\n",
      "Layer shape: (3, 3, 64, 128)\n",
      "2017-08-16 20:15:16,283 INFO Creating Summary for: conv2_1/filter\n",
      "2017-08-16 20:15:16,302 INFO Creating Summary for: conv2_1/biases\n",
      "Layer name: conv2_2\n",
      "Layer shape: (3, 3, 128, 128)\n",
      "2017-08-16 20:15:16,325 INFO Creating Summary for: conv2_2/filter\n",
      "2017-08-16 20:15:16,342 INFO Creating Summary for: conv2_2/biases\n",
      "Layer name: conv3_1\n",
      "Layer shape: (3, 3, 128, 256)\n",
      "2017-08-16 20:15:16,367 INFO Creating Summary for: conv3_1/filter\n",
      "2017-08-16 20:15:16,384 INFO Creating Summary for: conv3_1/biases\n",
      "Layer name: conv3_2\n",
      "Layer shape: (3, 3, 256, 256)\n",
      "2017-08-16 20:15:16,411 INFO Creating Summary for: conv3_2/filter\n",
      "2017-08-16 20:15:16,429 INFO Creating Summary for: conv3_2/biases\n",
      "Layer name: conv3_3\n",
      "Layer shape: (3, 3, 256, 256)\n",
      "2017-08-16 20:15:16,453 INFO Creating Summary for: conv3_3/filter\n",
      "2017-08-16 20:15:16,471 INFO Creating Summary for: conv3_3/biases\n",
      "Layer name: conv4_1\n",
      "Layer shape: (3, 3, 256, 512)\n",
      "2017-08-16 20:15:16,499 INFO Creating Summary for: conv4_1/filter\n",
      "2017-08-16 20:15:16,517 INFO Creating Summary for: conv4_1/biases\n",
      "Layer name: conv4_2\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-08-16 20:15:16,552 INFO Creating Summary for: conv4_2/filter\n",
      "2017-08-16 20:15:16,569 INFO Creating Summary for: conv4_2/biases\n",
      "Layer name: conv4_3\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-08-16 20:15:16,603 INFO Creating Summary for: conv4_3/filter\n",
      "2017-08-16 20:15:16,621 INFO Creating Summary for: conv4_3/biases\n",
      "Layer name: conv5_1\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-08-16 20:15:16,652 INFO Creating Summary for: conv5_1/filter\n",
      "2017-08-16 20:15:16,669 INFO Creating Summary for: conv5_1/biases\n",
      "Layer name: conv5_2\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-08-16 20:15:16,699 INFO Creating Summary for: conv5_2/filter\n",
      "2017-08-16 20:15:16,717 INFO Creating Summary for: conv5_2/biases\n",
      "Layer name: conv5_3\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-08-16 20:15:16,747 INFO Creating Summary for: conv5_3/filter\n",
      "2017-08-16 20:15:16,766 INFO Creating Summary for: conv5_3/biases\n",
      "Layer name: fc6\n",
      "Layer shape: [7, 7, 512, 4096]\n",
      "2017-08-16 20:15:17,287 INFO Creating Summary for: fc6/weights\n",
      "2017-08-16 20:15:17,304 INFO Creating Summary for: fc6/biases\n",
      "Layer name: fc7\n",
      "Layer shape: [1, 1, 4096, 4096]\n",
      "2017-08-16 20:15:17,417 INFO Creating Summary for: fc7/weights\n",
      "2017-08-16 20:15:17,435 INFO Creating Summary for: fc7/biases\n",
      "2017-08-16 20:15:17,467 INFO Creating Summary for: score_fr/weights\n",
      "2017-08-16 20:15:17,486 INFO Creating Summary for: score_fr/biases\n",
      "2017-08-16 20:15:17,519 INFO Creating Summary for: upscore2/up_filter\n",
      "2017-08-16 20:15:17,545 INFO Creating Summary for: score_pool4/weights\n",
      "2017-08-16 20:15:17,563 INFO Creating Summary for: score_pool4/biases\n",
      "2017-08-16 20:15:17,595 INFO Creating Summary for: upscore4/up_filter\n",
      "2017-08-16 20:15:17,621 INFO Creating Summary for: score_pool3/weights\n",
      "2017-08-16 20:15:17,638 INFO Creating Summary for: score_pool3/biases\n",
      "2017-08-16 20:15:17,670 INFO Creating Summary for: upscore32/up_filter\n"
     ]
    }
   ],
   "source": [
    "!~/anaconda2/bin/python  train.py --hypes hypes/KittiSeg.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
