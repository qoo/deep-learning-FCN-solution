{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: Not a git repository (or any parent up to mount point /mnt)\r\n",
      "Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\r\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/MarvinTeichmann/KittiSeg\n",
    "!git submodule update --init --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  449M  100  449M    0     0   9.7M      0  0:00:45  0:00:45 --:--:--  9.9M\n"
     ]
    }
   ],
   "source": [
    "#! curl -O  http://kitti.is.tue.mpg.de/kitti/data_road.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-31 19:29:35,941 INFO Downloading VGG weights.\n",
      "2017-07-31 19:29:35,942 INFO Download URL: ftp://mi.eng.cam.ac.uk/pub/mttt2/models/vgg16.npy\n",
      "2017-07-31 19:29:35,942 INFO Download DIR: DATA\n",
      ">> Downloading vgg16.npy 100.0%\n",
      "2017-07-31 19:30:06,349 INFO Downloading Kitti Road Data.\n",
      "2017-07-31 19:30:06,349 INFO Download URL: http://kitti.is.tue.mpg.de/kitti/data_road.zip\n",
      "2017-07-31 19:30:06,349 INFO Download DIR: DATA\n",
      ">> Downloading data_road.zip 100.0%\n",
      "2017-07-31 19:31:07,251 INFO Extracting kitti_road data.\n",
      "2017-07-31 19:31:10,760 INFO Preparing kitti_road data.\n",
      "2017-07-31 19:31:10,760 INFO All data have been downloaded successful.\n"
     ]
    }
   ],
   "source": [
    "!python download_data.py --kitti_url http://kitti.is.tue.mpg.de/kitti/data_road.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-31 19:32:16,396 INFO No environment variable 'TV_PLUGIN_DIR' found. Set to '/home/ubuntu/tv-plugins'.\n",
      "2017-07-31 19:32:16,396 INFO No environment variable 'TV_STEP_SHOW' found. Set to '50'.\n",
      "2017-07-31 19:32:16,396 INFO No environment variable 'TV_STEP_EVAL' found. Set to '250'.\n",
      "2017-07-31 19:32:16,396 INFO No environment variable 'TV_STEP_WRITE' found. Set to '1000'.\n",
      "2017-07-31 19:32:16,396 INFO No environment variable 'TV_MAX_KEEP' found. Set to '10'.\n",
      "2017-07-31 19:32:16,396 INFO No environment variable 'TV_STEP_STR' found. Set to 'Step {step}/{total_steps}: loss = {loss_value:.2f}; lr = {lr_value:.2e}; {sec_per_batch:.3f} sec (per Batch); {examples_per_sec:.1f} imgs/sec'.\n",
      "2017-07-31 19:32:16,398 INFO Download URL: ftp://mi.eng.cam.ac.uk/pub/mttt2/models/KittiSeg_pretrained.zip\n",
      "2017-07-31 19:32:16,398 INFO Download DIR: RUNS\n",
      "Traceback (most recent call last):\n",
      "  File \"demo.py\", line 227, in <module>\n",
      "    tf.app.run()\n",
      "  File \"/usr/local/anaconda3/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 48, in run\n",
      "    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\n",
      "  File \"demo.py\", line 124, in main\n",
      "    maybe_download_and_extract(runs_dir)\n",
      "  File \"demo.py\", line 87, in maybe_download_and_extract\n",
      "    download_name = tv_utils.download(weights_url, runs_dir)\n",
      "  File \"incl/tensorvision/utils.py\", line 48, in download\n",
      "    reporthook=_progress)\n",
      "  File \"/usr/local/anaconda3/lib/python3.5/urllib/request.py\", line 198, in urlretrieve\n",
      "    tfp = open(filename, 'wb')\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'RUNS/KittiSeg_pretrained.zip'\n"
     ]
    }
   ],
   "source": [
    "!python demo.py --input_image data/demo/demo.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2627M  100 2627M    0     0  16.9M      0  0:02:35  0:02:35 --:--:-- 17.5M\n"
     ]
    }
   ],
   "source": [
    "! curl -O  ftp://mi.eng.cam.ac.uk/pub/mttt2/models/KittiSeg_pretrained.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"maybe_download_and_extract(runs_dir):\"\"\"\n",
    "import zipfile\n",
    "runs_dir = 'RUNS'\n",
    "download_name = 'KittiSeg_pretrained.zip'\n",
    "zipfile.ZipFile(download_name, 'r').extractall(runs_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-31 19:45:36,035 INFO No environment variable 'TV_PLUGIN_DIR' found. Set to '/home/ubuntu/tv-plugins'.\n",
      "2017-07-31 19:45:36,035 INFO No environment variable 'TV_STEP_SHOW' found. Set to '50'.\n",
      "2017-07-31 19:45:36,035 INFO No environment variable 'TV_STEP_EVAL' found. Set to '250'.\n",
      "2017-07-31 19:45:36,035 INFO No environment variable 'TV_STEP_WRITE' found. Set to '1000'.\n",
      "2017-07-31 19:45:36,035 INFO No environment variable 'TV_MAX_KEEP' found. Set to '10'.\n",
      "2017-07-31 19:45:36,035 INFO No environment variable 'TV_STEP_STR' found. Set to 'Step {step}/{total_steps}: loss = {loss_value:.2f}; lr = {lr_value:.2e}; {sec_per_batch:.3f} sec (per Batch); {examples_per_sec:.1f} imgs/sec'.\n",
      "2017-07-31 19:45:36,036 INFO f: <_io.TextIOWrapper name='RUNS/KittiSeg_pretrained/model_files/hypes.json' mode='r' encoding='UTF-8'>\n",
      "2017-07-31 19:45:36,036 INFO Hypes loaded successfully.\n",
      "2017-07-31 19:45:36,049 INFO Modules loaded successfully. Starting to build tf graph.\n",
      "npy file loaded\n",
      "Layer name: conv1_1\n",
      "Layer shape: (3, 3, 3, 64)\n",
      "2017-07-31 19:45:36,724 INFO Creating Summary for: conv1_1/filter\n",
      "2017-07-31 19:45:36,743 INFO Creating Summary for: conv1_1/biases\n",
      "Layer name: conv1_2\n",
      "Layer shape: (3, 3, 64, 64)\n",
      "2017-07-31 19:45:36,766 INFO Creating Summary for: conv1_2/filter\n",
      "2017-07-31 19:45:36,783 INFO Creating Summary for: conv1_2/biases\n",
      "Layer name: conv2_1\n",
      "Layer shape: (3, 3, 64, 128)\n",
      "2017-07-31 19:45:36,807 INFO Creating Summary for: conv2_1/filter\n",
      "2017-07-31 19:45:36,824 INFO Creating Summary for: conv2_1/biases\n",
      "Layer name: conv2_2\n",
      "Layer shape: (3, 3, 128, 128)\n",
      "2017-07-31 19:45:36,847 INFO Creating Summary for: conv2_2/filter\n",
      "2017-07-31 19:45:36,864 INFO Creating Summary for: conv2_2/biases\n",
      "Layer name: conv3_1\n",
      "Layer shape: (3, 3, 128, 256)\n",
      "2017-07-31 19:45:36,889 INFO Creating Summary for: conv3_1/filter\n",
      "2017-07-31 19:45:36,906 INFO Creating Summary for: conv3_1/biases\n",
      "Layer name: conv3_2\n",
      "Layer shape: (3, 3, 256, 256)\n",
      "2017-07-31 19:45:36,933 INFO Creating Summary for: conv3_2/filter\n",
      "2017-07-31 19:45:36,950 INFO Creating Summary for: conv3_2/biases\n",
      "Layer name: conv3_3\n",
      "Layer shape: (3, 3, 256, 256)\n",
      "2017-07-31 19:45:36,975 INFO Creating Summary for: conv3_3/filter\n",
      "2017-07-31 19:45:36,992 INFO Creating Summary for: conv3_3/biases\n",
      "Layer name: conv4_1\n",
      "Layer shape: (3, 3, 256, 512)\n",
      "2017-07-31 19:45:37,019 INFO Creating Summary for: conv4_1/filter\n",
      "2017-07-31 19:45:37,036 INFO Creating Summary for: conv4_1/biases\n",
      "Layer name: conv4_2\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-07-31 19:45:37,070 INFO Creating Summary for: conv4_2/filter\n",
      "2017-07-31 19:45:37,087 INFO Creating Summary for: conv4_2/biases\n",
      "Layer name: conv4_3\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-07-31 19:45:37,117 INFO Creating Summary for: conv4_3/filter\n",
      "2017-07-31 19:45:37,134 INFO Creating Summary for: conv4_3/biases\n",
      "Layer name: conv5_1\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-07-31 19:45:37,164 INFO Creating Summary for: conv5_1/filter\n",
      "2017-07-31 19:45:37,181 INFO Creating Summary for: conv5_1/biases\n",
      "Layer name: conv5_2\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-07-31 19:45:37,211 INFO Creating Summary for: conv5_2/filter\n",
      "2017-07-31 19:45:37,229 INFO Creating Summary for: conv5_2/biases\n",
      "Layer name: conv5_3\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-07-31 19:45:37,259 INFO Creating Summary for: conv5_3/filter\n",
      "2017-07-31 19:45:37,276 INFO Creating Summary for: conv5_3/biases\n",
      "Layer name: fc6\n",
      "Layer shape: [7, 7, 512, 4096]\n",
      "2017-07-31 19:45:37,790 INFO Creating Summary for: fc6/weights\n",
      "2017-07-31 19:45:37,808 INFO Creating Summary for: fc6/biases\n",
      "Layer name: fc7\n",
      "Layer shape: [1, 1, 4096, 4096]\n",
      "2017-07-31 19:45:37,913 INFO Creating Summary for: fc7/weights\n",
      "2017-07-31 19:45:37,930 INFO Creating Summary for: fc7/biases\n",
      "2017-07-31 19:45:37,955 INFO Creating Summary for: score_fr/weights\n",
      "2017-07-31 19:45:37,973 INFO Creating Summary for: score_fr/biases\n",
      "2017-07-31 19:45:38,004 INFO Creating Summary for: upscore2/up_filter\n",
      "2017-07-31 19:45:38,030 INFO Creating Summary for: score_pool4/weights\n",
      "2017-07-31 19:45:38,047 INFO Creating Summary for: score_pool4/biases\n",
      "2017-07-31 19:45:38,078 INFO Creating Summary for: upscore4/up_filter\n",
      "2017-07-31 19:45:38,103 INFO Creating Summary for: score_pool3/weights\n",
      "2017-07-31 19:45:38,120 INFO Creating Summary for: score_pool3/biases\n",
      "2017-07-31 19:45:38,152 INFO Creating Summary for: upscore32/up_filter\n",
      "2017-07-31 19:45:38,176 INFO Graph build successfully.\n",
      "2017-07-31 19:45:38.177096: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-31 19:45:38.177136: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-31 19:45:38.177151: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-31 19:45:38.177163: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-31 19:45:38.177174: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-31 19:45:38.420820: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2017-07-31 19:45:38.421351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: \n",
      "name: Tesla K80\n",
      "major: 3 minor: 7 memoryClockRate (GHz) 0.8235\n",
      "pciBusID 0000:00:1e.0\n",
      "Total memory: 11.17GiB\n",
      "Free memory: 11.11GiB\n",
      "2017-07-31 19:45:38.421405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \n",
      "2017-07-31 19:45:38.421420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \n",
      "2017-07-31 19:45:38.421439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0)\n",
      "2017-07-31 19:45:38,567 INFO /u/marvin/no_backup/RUNS/KittiSeg/loss_bench/xentropy_kitti_fcn_2016_10_15_01.18/model.ckpt-15999\n",
      "INFO:tensorflow:Restoring parameters from RUNS/KittiSeg_pretrained/model.ckpt-15999\n",
      "2017-07-31 19:45:38,567 INFO Restoring parameters from RUNS/KittiSeg_pretrained/model.ckpt-15999\n",
      "2017-07-31 19:45:40,819 INFO Weights loaded successfully.\n",
      "2017-07-31 19:45:40,819 INFO Starting inference using data/demo/demo.png as input\n",
      "2017-07-31 19:45:45,562 INFO \n",
      "2017-07-31 19:45:45,563 INFO Raw output image has been saved to: /mnt/KittiSeg/data/demo/demo_raw.png\n",
      "2017-07-31 19:45:45,563 INFO Red-Blue overlay of confs have been saved to: /mnt/KittiSeg/data/demo/demo_rb.png\n",
      "2017-07-31 19:45:45,563 INFO Green plot of predictions have been saved to: /mnt/KittiSeg/data/demo/demo_green.png\n",
      "2017-07-31 19:45:45,563 INFO \n",
      "2017-07-31 19:45:45,563 WARNING Do NOT use this Code to evaluate multiple images.\n",
      "2017-07-31 19:45:45,563 WARNING Demo.py is **very slow** and designed to be a tutorial to show how the KittiSeg works.\n",
      "2017-07-31 19:45:45,563 WARNING \n",
      "2017-07-31 19:45:45,563 WARNING Please see this comment, if you like to apply demo.py tomultiple images see:\n",
      "2017-07-31 19:45:45,563 WARNING https://github.com/MarvinTeichmann/KittiBox/issues/15#issuecomment-301800058\n"
     ]
    }
   ],
   "source": [
    "!python demo.py --input_image data/demo/demo.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-31 20:24:28,769 INFO No environment variable 'TV_PLUGIN_DIR' found. Set to '/home/ubuntu/tv-plugins'.\n",
      "2017-07-31 20:24:28,769 INFO No environment variable 'TV_STEP_SHOW' found. Set to '50'.\n",
      "2017-07-31 20:24:28,769 INFO No environment variable 'TV_STEP_EVAL' found. Set to '250'.\n",
      "2017-07-31 20:24:28,769 INFO No environment variable 'TV_STEP_WRITE' found. Set to '1000'.\n",
      "2017-07-31 20:24:28,770 INFO No environment variable 'TV_MAX_KEEP' found. Set to '10'.\n",
      "2017-07-31 20:24:28,770 INFO No environment variable 'TV_STEP_STR' found. Set to 'Step {step}/{total_steps}: loss = {loss_value:.2f}; lr = {lr_value:.2e}; {sec_per_batch:.3f} sec (per Batch); {examples_per_sec:.1f} imgs/sec'.\n",
      "2017-07-31 20:24:28,770 INFO f: <_io.TextIOWrapper name='RUNS/KittiSeg_pretrained/model_files/hypes.json' mode='r' encoding='UTF-8'>\n",
      "2017-07-31 20:24:28,771 INFO Hypes loaded successfully.\n",
      "2017-07-31 20:24:28,773 INFO Modules loaded successfully. Starting to build tf graph.\n",
      "npy file loaded\n",
      "Layer name: conv1_1\n",
      "Layer shape: (3, 3, 3, 64)\n",
      "2017-07-31 20:24:29,429 INFO Creating Summary for: conv1_1/filter\n",
      "2017-07-31 20:24:29,449 INFO Creating Summary for: conv1_1/biases\n",
      "Layer name: conv1_2\n",
      "Layer shape: (3, 3, 64, 64)\n",
      "2017-07-31 20:24:29,473 INFO Creating Summary for: conv1_2/filter\n",
      "2017-07-31 20:24:29,490 INFO Creating Summary for: conv1_2/biases\n",
      "Layer name: conv2_1\n",
      "Layer shape: (3, 3, 64, 128)\n",
      "2017-07-31 20:24:29,514 INFO Creating Summary for: conv2_1/filter\n",
      "2017-07-31 20:24:29,531 INFO Creating Summary for: conv2_1/biases\n",
      "Layer name: conv2_2\n",
      "Layer shape: (3, 3, 128, 128)\n",
      "2017-07-31 20:24:29,553 INFO Creating Summary for: conv2_2/filter\n",
      "2017-07-31 20:24:29,570 INFO Creating Summary for: conv2_2/biases\n",
      "Layer name: conv3_1\n",
      "Layer shape: (3, 3, 128, 256)\n",
      "2017-07-31 20:24:29,594 INFO Creating Summary for: conv3_1/filter\n",
      "2017-07-31 20:24:29,611 INFO Creating Summary for: conv3_1/biases\n",
      "Layer name: conv3_2\n",
      "Layer shape: (3, 3, 256, 256)\n",
      "2017-07-31 20:24:29,637 INFO Creating Summary for: conv3_2/filter\n",
      "2017-07-31 20:24:29,654 INFO Creating Summary for: conv3_2/biases\n",
      "Layer name: conv3_3\n",
      "Layer shape: (3, 3, 256, 256)\n",
      "2017-07-31 20:24:29,678 INFO Creating Summary for: conv3_3/filter\n",
      "2017-07-31 20:24:29,695 INFO Creating Summary for: conv3_3/biases\n",
      "Layer name: conv4_1\n",
      "Layer shape: (3, 3, 256, 512)\n",
      "2017-07-31 20:24:29,722 INFO Creating Summary for: conv4_1/filter\n",
      "2017-07-31 20:24:29,739 INFO Creating Summary for: conv4_1/biases\n",
      "Layer name: conv4_2\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-07-31 20:24:29,773 INFO Creating Summary for: conv4_2/filter\n",
      "2017-07-31 20:24:29,790 INFO Creating Summary for: conv4_2/biases\n",
      "Layer name: conv4_3\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-07-31 20:24:29,819 INFO Creating Summary for: conv4_3/filter\n",
      "2017-07-31 20:24:29,836 INFO Creating Summary for: conv4_3/biases\n",
      "Layer name: conv5_1\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-07-31 20:24:29,866 INFO Creating Summary for: conv5_1/filter\n",
      "2017-07-31 20:24:29,883 INFO Creating Summary for: conv5_1/biases\n",
      "Layer name: conv5_2\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-07-31 20:24:29,913 INFO Creating Summary for: conv5_2/filter\n",
      "2017-07-31 20:24:29,930 INFO Creating Summary for: conv5_2/biases\n",
      "Layer name: conv5_3\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "2017-07-31 20:24:29,959 INFO Creating Summary for: conv5_3/filter\n",
      "2017-07-31 20:24:29,977 INFO Creating Summary for: conv5_3/biases\n",
      "Layer name: fc6\n",
      "Layer shape: [7, 7, 512, 4096]\n",
      "2017-07-31 20:24:30,491 INFO Creating Summary for: fc6/weights\n",
      "2017-07-31 20:24:30,509 INFO Creating Summary for: fc6/biases\n",
      "Layer name: fc7\n",
      "Layer shape: [1, 1, 4096, 4096]\n",
      "2017-07-31 20:24:30,618 INFO Creating Summary for: fc7/weights\n",
      "2017-07-31 20:24:30,635 INFO Creating Summary for: fc7/biases\n",
      "2017-07-31 20:24:30,660 INFO Creating Summary for: score_fr/weights\n",
      "2017-07-31 20:24:30,677 INFO Creating Summary for: score_fr/biases\n",
      "2017-07-31 20:24:30,708 INFO Creating Summary for: upscore2/up_filter\n",
      "2017-07-31 20:24:30,734 INFO Creating Summary for: score_pool4/weights\n",
      "2017-07-31 20:24:30,751 INFO Creating Summary for: score_pool4/biases\n",
      "2017-07-31 20:24:30,781 INFO Creating Summary for: upscore4/up_filter\n",
      "2017-07-31 20:24:30,806 INFO Creating Summary for: score_pool3/weights\n",
      "2017-07-31 20:24:30,823 INFO Creating Summary for: score_pool3/biases\n",
      "2017-07-31 20:24:30,854 INFO Creating Summary for: upscore32/up_filter\n",
      "2017-07-31 20:24:30,878 INFO Graph build successfully.\n",
      "2017-07-31 20:24:30.879029: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-31 20:24:30.879068: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-31 20:24:30.879082: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-31 20:24:30.879094: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-31 20:24:30.879105: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "2017-07-31 20:24:31.065798: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2017-07-31 20:24:31.066347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties: \n",
      "name: Tesla K80\n",
      "major: 3 minor: 7 memoryClockRate (GHz) 0.8235\n",
      "pciBusID 0000:00:1e.0\n",
      "Total memory: 11.17GiB\n",
      "Free memory: 11.11GiB\n",
      "2017-07-31 20:24:31.066400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0 \n",
      "2017-07-31 20:24:31.066415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y \n",
      "2017-07-31 20:24:31.066434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0)\n",
      "2017-07-31 20:24:31,208 INFO /u/marvin/no_backup/RUNS/KittiSeg/loss_bench/xentropy_kitti_fcn_2016_10_15_01.18/model.ckpt-15999\n",
      "INFO:tensorflow:Restoring parameters from RUNS/KittiSeg_pretrained/model.ckpt-15999\n",
      "2017-07-31 20:24:31,208 INFO Restoring parameters from RUNS/KittiSeg_pretrained/model.ckpt-15999\n",
      "2017-07-31 20:24:33,275 INFO Weights loaded successfully.\n",
      "2017-07-31 20:24:33,275 INFO Starting inference using data/demo/test2.png as input\n",
      "2017-07-31 20:24:35,138 INFO \n",
      "2017-07-31 20:24:35,138 INFO Raw output image has been saved to: /mnt/KittiSeg/data/demo/test2_raw.png\n",
      "2017-07-31 20:24:35,138 INFO Red-Blue overlay of confs have been saved to: /mnt/KittiSeg/data/demo/test2_rb.png\n",
      "2017-07-31 20:24:35,138 INFO Green plot of predictions have been saved to: /mnt/KittiSeg/data/demo/test2_green.png\n",
      "2017-07-31 20:24:35,138 INFO \n",
      "2017-07-31 20:24:35,138 WARNING Do NOT use this Code to evaluate multiple images.\n",
      "2017-07-31 20:24:35,139 WARNING Demo.py is **very slow** and designed to be a tutorial to show how the KittiSeg works.\n",
      "2017-07-31 20:24:35,139 WARNING \n",
      "2017-07-31 20:24:35,139 WARNING Please see this comment, if you like to apply demo.py tomultiple images see:\n",
      "2017-07-31 20:24:35,139 WARNING https://github.com/MarvinTeichmann/KittiBox/issues/15#issuecomment-301800058\n"
     ]
    }
   ],
   "source": [
    "\"\"\"test google image\"\"\"\n",
    "!python demo.py --input_image data/demo/test2.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import commentjson\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"train.py\", line 18, in <module>\r\n",
      "    import commentjson\r\n",
      "  File \"/usr/local/anaconda3/lib/python3.5/site-packages/commentjson/__init__.py\", line 1, in <module>\r\n",
      "    from commentjson import dump\r\n",
      "ImportError: cannot import name 'dump'\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --hypes hypes/KittiSeg.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting commentjson\n",
      "  Downloading commentjson-0.6.tar.gz\n",
      "Building wheels for collected packages: commentjson\n",
      "  Running setup.py bdist_wheel for commentjson ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/ubuntu/.cache/pip/wheels/d4/8e/dc/4a85a7fd1d9c8e161987399ead8a56f95042faba79d1f436c3\n",
      "Successfully built commentjson\n",
      "Installing collected packages: commentjson\n",
      "Successfully installed commentjson-0.6\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install commentjson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dump\n",
      "  Using cached dump-0.0.1.tar.gz\n",
      "    Complete output from command python setup.py egg_info:\n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-build-qjp3d40t/dump/setup.py\", line 12, in <module>\n",
      "        for node in (n for n in ast.parse(f.read()).body if isinstance(n, ast.Assign)):\n",
      "      File \"/usr/local/anaconda3/lib/python3.5/ast.py\", line 35, in parse\n",
      "        return compile(source, filename, mode, PyCF_ONLY_AST)\n",
      "      File \"<unknown>\", line 70\n",
      "        print \"This should be the help part that prints out all the commands\"\n",
      "                                                                            ^\n",
      "    SyntaxError: Missing parentheses in call to 'print'\n",
      "    \n",
      "    ----------------------------------------\n",
      "\u001b[31mCommand \"python setup.py egg_info\" failed with error code 1 in /tmp/pip-build-qjp3d40t/dump/\u001b[0m\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"train.py\", line 18, in <module>\r\n",
      "    import commentjson\r\n",
      "  File \"/usr/local/anaconda3/lib/python3.5/site-packages/commentjson/__init__.py\", line 1, in <module>\r\n",
      "    from commentjson import dump\r\n",
      "ImportError: cannot import name 'dump'\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --hypes hypes/KittiSeg.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\r\n",
      "  File \"train.py\", line 18, in <module>\r\n",
      "    import commentjson\r\n",
      "  File \"/usr/local/anaconda3/lib/python3.5/site-packages/commentjson/__init__.py\", line 1, in <module>\r\n",
      "    from commentjson import dump\r\n",
      "ImportError: cannot import name 'dump'\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --hypes hypes/KittiSeg.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
